# Prathamesh's Droid

A simple LLM driven slack bot that replies to your messages with a response generated by a LLM.

# Current Functionality
- Detects if a message is a question and replies with a response generated by a LLM.
- Sends the last 5 messages along with the previous bot responses to the LLM for proper context.
- Can be installed on multiple slack workspaces.

# Tech Stack
- Server: Python (Flask)
- LLM: Gemini Flash 2.0 with Langchain
- Hosting: GCP VM with Ngrok Tunnel

# To-Do
- [ ] Slack OAuth2 token management is currently done in-memory. Needs to be moved to a database.
- [ ] Once the token management is moved to a database, the server can be hosted on a serverless service.
- [ ] Make the message sending functionality async so that server can respond to Slack server quickly.

